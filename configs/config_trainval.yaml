project:
  output_base_path: "/mnt/data/anmol/Lightpipe/output/dataset_trainval/"
  seed: 42 # Seed for reproducible train/val splits

assets:
  # Asset paths are specific to your machine, so they remain unchanged.
  objects_dir: "/mnt/data/anmol/DecorativeModels/"
  materials_dir: "/mnt/data/anmol/Lightpipe/materials/"
  hdri_dir: "/mnt/data/anmol/Lightpipe"

settings:
  num_videos: 50 # Total number of videos to generate
  frames_per_video: 77 # Frames per video
  resolution:
    width: 1200
    height: 800
  # Train/Validation split configuration
  dataset_split:
    train_ratio: 0.8 # 80% for training, 20% for validation
    ensure_disjoint_assets: true # Ensure objects/HDRIs don't overlap between train/val
  # Camera settings
  camera_settings:
    type: "static" # For now, reflects the current main.py implementation
    poi: [0, 0, 1.0] # Point of Interest the camera looks at
    angle_range: [-60, 60] # Vertical angle range for camera
    orbit_radius: 8.0 # Radius for camera orbit around the scene
    camera_height: [1.0, 3.0] # Height of the camera above the ground

randomization:
  # Each light path is now an object with its own parameters for more control.
  path_types:
    - "LEFT_ORBIT"
    - "RIGHT_ORBIT"
    - "FIGURE_EIGHT"
      # You could add more parameters here, like height variation
  orbit_radius_range: [1.0, 1.5] # Range for orbit radius
  height_variation: 0.5
  light_properties:
    intensity_range: [1000, 2000] # Range for light intensity
    color_variation: [0.8, 1.2] # Variation factor for light color
